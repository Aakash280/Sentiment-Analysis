{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnMdYBZ4V3Pe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VW8t0hBYWGko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41e72cd-5f36-4eeb-e64a-e663fbfbdf14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8zuj2MZjrwE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "f054f7fd-b3a9-47e4-abd0-3fff7729effa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                product_name  \\\n",
              "0          20  PRETTYGARDEN Womens Casual Bodycon Pockets   \n",
              "1          21  PRETTYGARDEN Womens Casual Bodycon Pockets   \n",
              "2          22  PRETTYGARDEN Womens Casual Bodycon Pockets   \n",
              "3          23  PRETTYGARDEN Womens Casual Bodycon Pockets   \n",
              "4          24  PRETTYGARDEN Womens Casual Bodycon Pockets   \n",
              "\n",
              "                  review_title  \\\n",
              "0                        Yes!!   \n",
              "1              Beautiful dress   \n",
              "2                Great fitting   \n",
              "3  Most comfortable dress ever   \n",
              "4                      Love it   \n",
              "\n",
              "                                             comment              rating  \\\n",
              "0  I received so many compliments on this dress! ...  5.0 out of 5 stars   \n",
              "1  I love this dress, wore it to an office and it...  5.0 out of 5 stars   \n",
              "2  It's very flattering, especially for girls wit...  5.0 out of 5 stars   \n",
              "3  This fit in all of the right places.  So flatt...  5.0 out of 5 stars   \n",
              "4  I love this dress so much I had to get it in r...  5.0 out of 5 stars   \n",
              "\n",
              "               date            username  \\\n",
              "0  February 9, 2023               Kedra   \n",
              "1  February 8, 2023  M. C. Miranda Leon   \n",
              "2  February 8, 2023              B Cast   \n",
              "3  February 7, 2023     Michele Smading   \n",
              "4  February 5, 2023       Octavia Davis   \n",
              "\n",
              "                                         profile_url  verified_purchase  \n",
              "0  https://amazon.com//gp/profile/amzn1.account.A...               True  \n",
              "1  https://amazon.com//gp/profile/amzn1.account.A...               True  \n",
              "2  https://amazon.com//gp/profile/amzn1.account.A...               True  \n",
              "3  https://amazon.com//gp/profile/amzn1.account.A...               True  \n",
              "4  https://amazon.com//gp/profile/amzn1.account.A...               True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f52c3d2-ac1d-482f-bb0d-3e0fc812fc07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>product_name</th>\n",
              "      <th>review_title</th>\n",
              "      <th>comment</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>username</th>\n",
              "      <th>profile_url</th>\n",
              "      <th>verified_purchase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>PRETTYGARDEN Womens Casual Bodycon Pockets</td>\n",
              "      <td>Yes!!</td>\n",
              "      <td>I received so many compliments on this dress! ...</td>\n",
              "      <td>5.0 out of 5 stars</td>\n",
              "      <td>February 9, 2023</td>\n",
              "      <td>Kedra</td>\n",
              "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>PRETTYGARDEN Womens Casual Bodycon Pockets</td>\n",
              "      <td>Beautiful dress</td>\n",
              "      <td>I love this dress, wore it to an office and it...</td>\n",
              "      <td>5.0 out of 5 stars</td>\n",
              "      <td>February 8, 2023</td>\n",
              "      <td>M. C. Miranda Leon</td>\n",
              "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>PRETTYGARDEN Womens Casual Bodycon Pockets</td>\n",
              "      <td>Great fitting</td>\n",
              "      <td>It's very flattering, especially for girls wit...</td>\n",
              "      <td>5.0 out of 5 stars</td>\n",
              "      <td>February 8, 2023</td>\n",
              "      <td>B Cast</td>\n",
              "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>23</td>\n",
              "      <td>PRETTYGARDEN Womens Casual Bodycon Pockets</td>\n",
              "      <td>Most comfortable dress ever</td>\n",
              "      <td>This fit in all of the right places.  So flatt...</td>\n",
              "      <td>5.0 out of 5 stars</td>\n",
              "      <td>February 7, 2023</td>\n",
              "      <td>Michele Smading</td>\n",
              "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>PRETTYGARDEN Womens Casual Bodycon Pockets</td>\n",
              "      <td>Love it</td>\n",
              "      <td>I love this dress so much I had to get it in r...</td>\n",
              "      <td>5.0 out of 5 stars</td>\n",
              "      <td>February 5, 2023</td>\n",
              "      <td>Octavia Davis</td>\n",
              "      <td>https://amazon.com//gp/profile/amzn1.account.A...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f52c3d2-ac1d-482f-bb0d-3e0fc812fc07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f52c3d2-ac1d-482f-bb0d-3e0fc812fc07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f52c3d2-ac1d-482f-bb0d-3e0fc812fc07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Final Dataset.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWWmk7Q8wpEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15639611-6800-44cd-92d5-3efd2dc75f8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23910, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KssF0LUBWYRr"
      },
      "outputs": [],
      "source": [
        "df = df.drop(['Unnamed: 0'], axis=1)\n",
        "df = df.drop(['date'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu_RqW86WeM8"
      },
      "outputs": [],
      "source": [
        "df['Rating'] = np.where(df['rating'] == '3.0 out of 5 stars', '3.0',\n",
        "               np.where(df['rating'] == '1.0 out of 5 stars', '1.0',\n",
        "               np.where(df['rating'] == '2.0 out of 5 stars', '2.0',\n",
        "               np.where(df['rating'] == '4.0 out of 5 stars', '4.0',\n",
        "               np.where(df['rating'] == '5.0 out of 5 stars', '5.0','none')))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlZLbLqAWqOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a628ae6-fef6-4823-97c9-1e2c9b29126d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "product_name          object\n",
            "review_title          object\n",
            "comment               object\n",
            "rating                object\n",
            "username              object\n",
            "profile_url           object\n",
            "verified_purchase       bool\n",
            "Rating               float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "#convert the rating from object to integer type\n",
        "df = df.astype({'Rating':'float'})\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DywJfnSwWQVA"
      },
      "outputs": [],
      "source": [
        "text = df['comment'] #extracting the reviews\n",
        "label = df['Rating'] #extracting the ratings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tn-4YayiW9mC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "072f3f96-2865-463e-e835-8341c6804ac0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I received so many compliments on this dress! Fits well. Material is breathable and a descent quality.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "text[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCGec_wnXB2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7af1a29-eaea-452a-c21f-8eb389fc732b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23910"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_klynr1OXIeH"
      },
      "outputs": [],
      "source": [
        "#Tokenize — Create Vocab to Int mapping dictionary\n",
        "from collections import Counter\n",
        "all_text2 = ' '.join(text)\n",
        "# create a list of words\n",
        "words = all_text2.split()\n",
        "# Count all the words using Counter Method\n",
        "count_words = Counter(words)\n",
        "\n",
        "total_words = len(words)\n",
        "sorted_words = count_words.most_common(total_words)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52PS7tNkXOkx"
      },
      "outputs": [],
      "source": [
        "#In order to create a vocab to int mapping dictionary\n",
        "vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xir9Oq0TXRnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24729c7d-9502-48ba-b785-307e5511a821"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'I': 2,\n",
              " 'to': 3,\n",
              " 'and': 4,\n",
              " 'a': 5,\n",
              " 'it': 6,\n",
              " 'for': 7,\n",
              " 'is': 8,\n",
              " 'my': 9,\n",
              " 'of': 10,\n",
              " 'this': 11,\n",
              " 'in': 12,\n",
              " 'was': 13,\n",
              " 'with': 14,\n",
              " 'not': 15,\n",
              " 'on': 16,\n",
              " 'but': 17,\n",
              " 'that': 18,\n",
              " 'have': 19,\n",
              " 'you': 20,\n",
              " 'The': 21,\n",
              " 'as': 22,\n",
              " 'so': 23,\n",
              " 'be': 24,\n",
              " 'It': 25,\n",
              " 'are': 26,\n",
              " 'had': 27,\n",
              " 'use': 28,\n",
              " 'up': 29,\n",
              " 'laptop': 30,\n",
              " 'they': 31,\n",
              " 'or': 32,\n",
              " 'just': 33,\n",
              " 'This': 34,\n",
              " 'very': 35,\n",
              " 'get': 36,\n",
              " 'one': 37,\n",
              " 'at': 38,\n",
              " 'from': 39,\n",
              " 'no': 40,\n",
              " 'an': 41,\n",
              " 'great': 42,\n",
              " 'like': 43,\n",
              " 'work': 44,\n",
              " 'all': 45,\n",
              " 'good': 46,\n",
              " 'if': 47,\n",
              " 'me': 48,\n",
              " 'would': 49,\n",
              " 'out': 50,\n",
              " 'can': 51,\n",
              " 'will': 52,\n",
              " 'them': 53,\n",
              " 'has': 54,\n",
              " 'when': 55,\n",
              " 'drive': 56,\n",
              " 'only': 57,\n",
              " 'than': 58,\n",
              " 'these': 59,\n",
              " 'after': 60,\n",
              " 'do': 61,\n",
              " 'product': 62,\n",
              " 'bought': 63,\n",
              " 'about': 64,\n",
              " 'it.': 65,\n",
              " 'your': 66,\n",
              " 'works': 67,\n",
              " 'more': 68,\n",
              " 'computer': 69,\n",
              " 'easy': 70,\n",
              " 'what': 71,\n",
              " 'even': 72,\n",
              " 'because': 73,\n",
              " 'got': 74,\n",
              " 'time': 75,\n",
              " 'buy': 76,\n",
              " \"it's\": 77,\n",
              " 'really': 78,\n",
              " 'hard': 79,\n",
              " 'other': 80,\n",
              " 'did': 81,\n",
              " 'any': 82,\n",
              " 'could': 83,\n",
              " 'am': 84,\n",
              " 'which': 85,\n",
              " 'set': 86,\n",
              " 'quality': 87,\n",
              " 'still': 88,\n",
              " 'been': 89,\n",
              " 'used': 90,\n",
              " 'need': 91,\n",
              " 'some': 92,\n",
              " 'using': 93,\n",
              " 'back': 94,\n",
              " 'My': 95,\n",
              " 'now': 96,\n",
              " 'well': 97,\n",
              " 'does': 98,\n",
              " 'Great': 99,\n",
              " \"I'm\": 100,\n",
              " 'new': 101,\n",
              " 'working': 102,\n",
              " 'signal': 103,\n",
              " 'price': 104,\n",
              " 'much': 105,\n",
              " 'love': 106,\n",
              " 'then': 107,\n",
              " 'They': 108,\n",
              " 'were': 109,\n",
              " 'sound': 110,\n",
              " 'how': 111,\n",
              " \"don't\": 112,\n",
              " '2': 113,\n",
              " 'screen': 114,\n",
              " 'i': 115,\n",
              " 'storage': 116,\n",
              " 'extender': 117,\n",
              " 'never': 118,\n",
              " 'recommend': 119,\n",
              " 'better': 120,\n",
              " 'by': 121,\n",
              " 'wifi': 122,\n",
              " 'first': 123,\n",
              " 'So': 124,\n",
              " 'it’s': 125,\n",
              " 'Very': 126,\n",
              " 'little': 127,\n",
              " 'Works': 128,\n",
              " 'also': 129,\n",
              " 'into': 130,\n",
              " 'games': 131,\n",
              " 'connect': 132,\n",
              " 'battery': 133,\n",
              " 'device': 134,\n",
              " 'there': 135,\n",
              " 'few': 136,\n",
              " 'another': 137,\n",
              " \"I've\": 138,\n",
              " 'thing': 139,\n",
              " 'over': 140,\n",
              " 'right': 141,\n",
              " 'months': 142,\n",
              " 'tried': 143,\n",
              " 'worked': 144,\n",
              " 'able': 145,\n",
              " 'washer': 146,\n",
              " 'Acer': 147,\n",
              " 'its': 148,\n",
              " \"It's\": 149,\n",
              " '-': 150,\n",
              " 'If': 151,\n",
              " 'support': 152,\n",
              " 'same': 153,\n",
              " 'purchased': 154,\n",
              " 'two': 155,\n",
              " 'want': 156,\n",
              " 'router': 157,\n",
              " 'machine': 158,\n",
              " 'go': 159,\n",
              " 'our': 160,\n",
              " 'we': 161,\n",
              " 'Not': 162,\n",
              " 'needed': 163,\n",
              " 'too': 164,\n",
              " 'off': 165,\n",
              " 'return': 166,\n",
              " 'I’m': 167,\n",
              " 'know': 168,\n",
              " \"didn't\": 169,\n",
              " 'Easy': 170,\n",
              " 'work.': 171,\n",
              " '3': 172,\n",
              " 'since': 173,\n",
              " 'No': 174,\n",
              " '5': 175,\n",
              " 'going': 176,\n",
              " 'far': 177,\n",
              " 'Seagate': 178,\n",
              " 'everything': 179,\n",
              " 'without': 180,\n",
              " 'Windows': 181,\n",
              " 'great.': 182,\n",
              " 'fast': 183,\n",
              " 'sure': 184,\n",
              " 'make': 185,\n",
              " 'old': 186,\n",
              " 'external': 187,\n",
              " 'But': 188,\n",
              " 'before': 189,\n",
              " \"doesn't\": 190,\n",
              " 'purchase': 191,\n",
              " 'money': 192,\n",
              " 'nice': 193,\n",
              " 'happy': 194,\n",
              " 'way': 195,\n",
              " 'laptop.': 196,\n",
              " 'pretty': 197,\n",
              " 'every': 198,\n",
              " 'life': 199,\n",
              " 'long': 200,\n",
              " 'phone': 201,\n",
              " 'see': 202,\n",
              " 'lot': 203,\n",
              " \"can't\": 204,\n",
              " 'while': 205,\n",
              " 'came': 206,\n",
              " 'use.': 207,\n",
              " 'Amazon': 208,\n",
              " 'light': 209,\n",
              " 'stopped': 210,\n",
              " 'clean': 211,\n",
              " 'Apple': 212,\n",
              " 'their': 213,\n",
              " 'worth': 214,\n",
              " 'it,': 215,\n",
              " 'getting': 216,\n",
              " 'don’t': 217,\n",
              " 'last': 218,\n",
              " 'Good': 219,\n",
              " 'install': 220,\n",
              " 'years': 221,\n",
              " '10': 222,\n",
              " 'something': 223,\n",
              " 'through': 224,\n",
              " 'year': 225,\n",
              " 'tech': 226,\n",
              " 'dress': 227,\n",
              " 'keep': 228,\n",
              " 'issues': 229,\n",
              " 'different': 230,\n",
              " 'well.': 231,\n",
              " 'should': 232,\n",
              " 'having': 233,\n",
              " 'After': 234,\n",
              " 'up.': 235,\n",
              " 'AirPods': 236,\n",
              " 'Love': 237,\n",
              " '&': 238,\n",
              " 'de': 239,\n",
              " 'product.': 240,\n",
              " 'think': 241,\n",
              " 'many': 242,\n",
              " 'day': 243,\n",
              " 'Bought': 244,\n",
              " 'around': 245,\n",
              " 'You': 246,\n",
              " 'price.': 247,\n",
              " 'enough': 248,\n",
              " 'anything': 249,\n",
              " 'Just': 250,\n",
              " 'These': 251,\n",
              " 'speed': 252,\n",
              " 'connected': 253,\n",
              " 'being': 254,\n",
              " 'problem': 255,\n",
              " 'run': 256,\n",
              " 'files': 257,\n",
              " '4': 258,\n",
              " 'said': 259,\n",
              " 'put': 260,\n",
              " 'best': 261,\n",
              " 'We': 262,\n",
              " 'them.': 263,\n",
              " 'find': 264,\n",
              " 'help': 265,\n",
              " 'fit': 266,\n",
              " 'perfect': 267,\n",
              " 'washing': 268,\n",
              " 'super': 269,\n",
              " 'y': 270,\n",
              " 'It’s': 271,\n",
              " 'drive.': 272,\n",
              " 'keyboard': 273,\n",
              " 'me.': 274,\n",
              " 'take': 275,\n",
              " 'say': 276,\n",
              " 'try': 277,\n",
              " 'where': 278,\n",
              " 'internet': 279,\n",
              " 'went': 280,\n",
              " 'most': 281,\n",
              " 'took': 282,\n",
              " 'S': 283,\n",
              " 'plug': 284,\n",
              " 'once': 285,\n",
              " 'box': 286,\n",
              " 'When': 287,\n",
              " 'hours': 288,\n",
              " 'plugged': 289,\n",
              " 'issue': 290,\n",
              " 'data': 291,\n",
              " 'made': 292,\n",
              " 'less': 293,\n",
              " 'And': 294,\n",
              " 'play': 295,\n",
              " 'connection': 296,\n",
              " 'setup': 297,\n",
              " 'times': 298,\n",
              " 'down': 299,\n",
              " 'I’ve': 300,\n",
              " 'he': 301,\n",
              " 'A': 302,\n",
              " 'again.': 303,\n",
              " 'again': 304,\n",
              " 'always': 305,\n",
              " 'fine': 306,\n",
              " 'left': 307,\n",
              " 'brand': 308,\n",
              " 'computer.': 309,\n",
              " 'bit': 310,\n",
              " 'wanted': 311,\n",
              " 'gaming': 312,\n",
              " 'definitely': 313,\n",
              " 'second': 314,\n",
              " 'month': 315,\n",
              " 'buying': 316,\n",
              " 'didn’t': 317,\n",
              " 'ordered': 318,\n",
              " 'ear': 319,\n",
              " 'small': 320,\n",
              " 'case': 321,\n",
              " 'seems': 322,\n",
              " 'home': 323,\n",
              " 'extra': 324,\n",
              " '1': 325,\n",
              " 'pair': 326,\n",
              " 'who': 327,\n",
              " 'trying': 328,\n",
              " 'charge': 329,\n",
              " 'WiFi': 330,\n",
              " 'looking': 331,\n",
              " 'both': 332,\n",
              " 'memory': 333,\n",
              " 'time.': 334,\n",
              " 'NOT': 335,\n",
              " 'started': 336,\n",
              " 'For': 337,\n",
              " 'size': 338,\n",
              " 'bad': 339,\n",
              " 'house': 340,\n",
              " 'space': 341,\n",
              " 'several': 342,\n",
              " 'actually': 343,\n",
              " 'Netgear': 344,\n",
              " 'days': 345,\n",
              " 'nothing': 346,\n",
              " 'thought': 347,\n",
              " 'hear': 348,\n",
              " 'smell': 349,\n",
              " 'video': 350,\n",
              " 'USB': 351,\n",
              " 'ever': 352,\n",
              " 'may': 353,\n",
              " 'good.': 354,\n",
              " 'noise': 355,\n",
              " 'full': 356,\n",
              " 'drives': 357,\n",
              " 'RAM': 358,\n",
              " 'give': 359,\n",
              " '.': 360,\n",
              " 'says': 361,\n",
              " 'reviews': 362,\n",
              " 'open': 363,\n",
              " 'couple': 364,\n",
              " 'all.': 365,\n",
              " 'doesn’t': 366,\n",
              " 'windows': 367,\n",
              " 'money.': 368,\n",
              " 'things': 369,\n",
              " 'instructions': 370,\n",
              " 'store': 371,\n",
              " 'upgrade': 372,\n",
              " 'waste': 373,\n",
              " 'already': 374,\n",
              " 'card': 375,\n",
              " 'found': 376,\n",
              " 'read': 377,\n",
              " 'people': 378,\n",
              " 'one.': 379,\n",
              " 'until': 380,\n",
              " 'download': 381,\n",
              " 'item': 382,\n",
              " 'job': 383,\n",
              " 'look': 384,\n",
              " 'comes': 385,\n",
              " 'received': 386,\n",
              " 'makes': 387,\n",
              " 'la': 388,\n",
              " 'range': 389,\n",
              " 'come': 390,\n",
              " 'longer': 391,\n",
              " 'she': 392,\n",
              " 'power': 393,\n",
              " 'backup': 394,\n",
              " 'turn': 395,\n",
              " 'service': 396,\n",
              " 'though': 397,\n",
              " 'problems': 398,\n",
              " 'feel': 399,\n",
              " 'why': 400,\n",
              " 'Now': 401,\n",
              " 'away': 402,\n",
              " 'doing': 403,\n",
              " 'low': 404,\n",
              " 'needs': 405,\n",
              " 'room': 406,\n",
              " 'SSD': 407,\n",
              " 'cleaning': 408,\n",
              " 'There': 409,\n",
              " 'add': 410,\n",
              " 'loves': 411,\n",
              " 'laptop,': 412,\n",
              " 'multiple': 413,\n",
              " 'apple': 414,\n",
              " 'running': 415,\n",
              " 'ram': 416,\n",
              " 'large': 417,\n",
              " 'Xbox': 418,\n",
              " '6': 419,\n",
              " 'stay': 420,\n",
              " 'school': 421,\n",
              " 'returned': 422,\n",
              " 'minutes': 423,\n",
              " 'slow': 424,\n",
              " 'almost': 425,\n",
              " 'this.': 426,\n",
              " 'online': 427,\n",
              " 'simple': 428,\n",
              " 'Microsoft': 429,\n",
              " 'mode': 430,\n",
              " 'cannot': 431,\n",
              " 'customer': 432,\n",
              " 'Wi-Fi': 433,\n",
              " 'working.': 434,\n",
              " 'next': 435,\n",
              " 'front': 436,\n",
              " 'music': 437,\n",
              " 'big': 438,\n",
              " 'installed': 439,\n",
              " 'que': 440,\n",
              " 'can’t': 441,\n",
              " \"won't\": 442,\n",
              " 'devices': 443,\n",
              " 'top': 444,\n",
              " 'pay': 445,\n",
              " 'probably': 446,\n",
              " 'cheap': 447,\n",
              " 'One': 448,\n",
              " ',': 449,\n",
              " 'touch': 450,\n",
              " 'expected': 451,\n",
              " 'her': 452,\n",
              " 'lost': 453,\n",
              " 'told': 454,\n",
              " 'high': 455,\n",
              " 'son': 456,\n",
              " \"you're\": 457,\n",
              " 'looks': 458,\n",
              " 'gave': 459,\n",
              " 'system': 460,\n",
              " 'end': 461,\n",
              " 'basic': 462,\n",
              " 'within': 463,\n",
              " 'All': 464,\n",
              " 'completely': 465,\n",
              " 'finally': 466,\n",
              " 'amazing': 467,\n",
              " 'purchase.': 468,\n",
              " 'cable': 469,\n",
              " 'unit': 470,\n",
              " 'out.': 471,\n",
              " 'Would': 472,\n",
              " 'laptops': 473,\n",
              " 'those': 474,\n",
              " 'least': 475,\n",
              " \"that's\": 476,\n",
              " 'access': 477,\n",
              " 'game': 478,\n",
              " 'Mac': 479,\n",
              " 'router.': 480,\n",
              " 'order': 481,\n",
              " 'someone': 482,\n",
              " 'Got': 483,\n",
              " 'Had': 484,\n",
              " 'fix': 485,\n",
              " 'videos': 486,\n",
              " 'extend': 487,\n",
              " 'speakers': 488,\n",
              " 'review': 489,\n",
              " 'As': 490,\n",
              " 'exactly': 491,\n",
              " 'quite': 492,\n",
              " 'easily': 493,\n",
              " 'highly': 494,\n",
              " 'weeks': 495,\n",
              " 'under': 496,\n",
              " 'warranty': 497,\n",
              " 'great!': 498,\n",
              " \"isn't\": 499,\n",
              " 'send': 500,\n",
              " 'let': 501,\n",
              " 'hold': 502,\n",
              " 'software': 503,\n",
              " 'such': 504,\n",
              " 'wireless': 505,\n",
              " 'up,': 506,\n",
              " 'perfectly': 507,\n",
              " 'PC': 508,\n",
              " 'might': 509,\n",
              " 'deal': 510,\n",
              " 'web': 511,\n",
              " 'call': 512,\n",
              " 'charging': 513,\n",
              " 'start': 514,\n",
              " 'el': 515,\n",
              " 'number': 516,\n",
              " 'decided': 517,\n",
              " 'his': 518,\n",
              " 'side': 519,\n",
              " 'media': 520,\n",
              " 'runs': 521,\n",
              " 'transfer': 522,\n",
              " 'it!': 523,\n",
              " 'Does': 524,\n",
              " 'issues.': 525,\n",
              " 'decent': 526,\n",
              " 'volume': 527,\n",
              " 'network': 528,\n",
              " 'wish': 529,\n",
              " 'seem': 530,\n",
              " 'replace': 531,\n",
              " 'load': 532,\n",
              " 'fine.': 533,\n",
              " 'great,': 534,\n",
              " 'quality.': 535,\n",
              " 'quick': 536,\n",
              " 'done': 537,\n",
              " 'on.': 538,\n",
              " 'disappointed': 539,\n",
              " 'sent': 540,\n",
              " 'absolutely': 541,\n",
              " \"wasn't\": 542,\n",
              " 'gets': 543,\n",
              " 'In': 544,\n",
              " 'muy': 545,\n",
              " 'Will': 546,\n",
              " '8': 547,\n",
              " 'due': 548,\n",
              " 'else': 549,\n",
              " 'week': 550,\n",
              " 'kept': 551,\n",
              " 'that.': 552,\n",
              " 'maybe': 553,\n",
              " 'switch': 554,\n",
              " 'products': 555,\n",
              " 'ears': 556,\n",
              " 'machine.': 557,\n",
              " 'supposed': 558,\n",
              " 'performance': 559,\n",
              " 'excellent': 560,\n",
              " 'ones': 561,\n",
              " 'drive,': 562,\n",
              " 'Do': 563,\n",
              " 'three': 564,\n",
              " 'reason': 565,\n",
              " 'value': 566,\n",
              " 'now.': 567,\n",
              " 'storage.': 568,\n",
              " 'cost': 569,\n",
              " 'signal.': 570,\n",
              " 'work,': 571,\n",
              " \"couldn't\": 572,\n",
              " 'para': 573,\n",
              " 'Only': 574,\n",
              " 'airpods': 575,\n",
              " 'model': 576,\n",
              " 'move': 577,\n",
              " 'gift': 578,\n",
              " 'en': 579,\n",
              " \"Don't\": 580,\n",
              " 'inside': 581,\n",
              " 'wear': 582,\n",
              " \"wouldn't\": 583,\n",
              " '30': 584,\n",
              " 'update': 585,\n",
              " 'tablets': 586,\n",
              " 'months.': 587,\n",
              " 'called': 588,\n",
              " 'However,': 589,\n",
              " 'What': 590,\n",
              " 'camera': 591,\n",
              " 'real': 592,\n",
              " 'He': 593,\n",
              " 'house.': 594,\n",
              " 'es': 595,\n",
              " \"I'll\": 596,\n",
              " 'sometimes': 597,\n",
              " 'won’t': 598,\n",
              " 'Worked': 599,\n",
              " 'especially': 600,\n",
              " '2nd': 601,\n",
              " 'headphones': 602,\n",
              " 'expensive': 603,\n",
              " 'half': 604,\n",
              " 'setting': 605,\n",
              " 'extremely': 606,\n",
              " 'between': 607,\n",
              " 'own': 608,\n",
              " 'use,': 609,\n",
              " 'That': 610,\n",
              " 'added': 611,\n",
              " 'tablet': 612,\n",
              " 'reset': 613,\n",
              " 'pods': 614,\n",
              " 'mouse': 615,\n",
              " 'tell': 616,\n",
              " 'amount': 617,\n",
              " 'quickly': 618,\n",
              " 'takes': 619,\n",
              " 'older': 620,\n",
              " 'additional': 621,\n",
              " 'GB': 622,\n",
              " 'pad': 623,\n",
              " 'portable': 624,\n",
              " 'Even': 625,\n",
              " 'anyone': 626,\n",
              " 'point': 627,\n",
              " 'main': 628,\n",
              " 'comfortable': 629,\n",
              " 'Then': 630,\n",
              " 'daughter': 631,\n",
              " 'these.': 632,\n",
              " 'loaded.': 633,\n",
              " 'option': 634,\n",
              " 'fits': 635,\n",
              " \"haven't\": 636,\n",
              " 'problem.': 637,\n",
              " 'Was': 638,\n",
              " 'during': 639,\n",
              " 'change': 640,\n",
              " 'backlit': 641,\n",
              " 'ago': 642,\n",
              " 'returning': 643,\n",
              " 'past': 644,\n",
              " 'unless': 645,\n",
              " 'format': 646,\n",
              " 'fast.': 647,\n",
              " 'arrived': 648,\n",
              " 'save': 649,\n",
              " 'spend': 650,\n",
              " 'compatible': 651,\n",
              " 'loud': 652,\n",
              " 'difference': 653,\n",
              " \"I'd\": 654,\n",
              " 'Product': 655,\n",
              " 'better.': 656,\n",
              " 'extender.': 657,\n",
              " 'color': 658,\n",
              " 'replacement': 659,\n",
              " 'whole': 660,\n",
              " 'stuff': 661,\n",
              " 'user': 662,\n",
              " 'failed': 663,\n",
              " 'Nice': 664,\n",
              " 'expect': 665,\n",
              " 'mine': 666,\n",
              " 'making': 667,\n",
              " 'show': 668,\n",
              " 'too.': 669,\n",
              " 'washer.': 670,\n",
              " 'budget': 671,\n",
              " 'keys': 672,\n",
              " 'wrong': 673,\n",
              " 'well,': 674,\n",
              " 'price,': 675,\n",
              " 'Battery': 676,\n",
              " 'must': 677,\n",
              " 'poor': 678,\n",
              " 'capacity': 679,\n",
              " 'disk': 680,\n",
              " 'connecting': 681,\n",
              " 'hour': 682,\n",
              " 'feet': 683,\n",
              " 'type': 684,\n",
              " 'short': 685,\n",
              " 'do.': 686,\n",
              " 'speeds': 687,\n",
              " 'security': 688,\n",
              " 'either': 689,\n",
              " 'lo': 690,\n",
              " 'air': 691,\n",
              " 'clear': 692,\n",
              " 'keeps': 693,\n",
              " 'Sound': 694,\n",
              " 'port': 695,\n",
              " 'Have': 696,\n",
              " 'pleased': 697,\n",
              " 'cycle': 698,\n",
              " 'photos': 699,\n",
              " 'website': 700,\n",
              " 'Perfect': 701,\n",
              " 'trouble': 702,\n",
              " 'for.': 703,\n",
              " 'uses': 704,\n",
              " 'later': 705,\n",
              " 'device.': 706,\n",
              " 'earbuds': 707,\n",
              " 'instead': 708,\n",
              " 'Super': 709,\n",
              " 'barely': 710,\n",
              " '20': 711,\n",
              " 'Did': 712,\n",
              " 'write': 713,\n",
              " 'Never': 714,\n",
              " 'Excellent': 715,\n",
              " 'Highly': 716,\n",
              " 'outside': 717,\n",
              " 'HD': 718,\n",
              " 'Aspire': 719,\n",
              " 'back.': 720,\n",
              " 'glad': 721,\n",
              " 'good,': 722,\n",
              " 'fall': 723,\n",
              " 'overall': 724,\n",
              " 'She': 725,\n",
              " 'normal': 726,\n",
              " 'each': 727,\n",
              " 'key': 728,\n",
              " 'settings': 729,\n",
              " 'computers': 730,\n",
              " 'solid': 731,\n",
              " 'button': 732,\n",
              " 'looked': 733,\n",
              " 'goes': 734,\n",
              " 'here': 735,\n",
              " 'Tried': 736,\n",
              " 'paid': 737,\n",
              " 'Once': 738,\n",
              " 'stop': 739,\n",
              " 'in.': 740,\n",
              " 'experience': 741,\n",
              " 'HDD': 742,\n",
              " 'wasn’t': 743,\n",
              " 'At': 744,\n",
              " 'apps': 745,\n",
              " 'TB': 746,\n",
              " 'screen.': 747,\n",
              " 'part': 748,\n",
              " 'loved': 749,\n",
              " 'noticed': 750,\n",
              " 'process': 751,\n",
              " 'original': 752,\n",
              " 'watch': 753,\n",
              " 'listen': 754,\n",
              " 'office': 755,\n",
              " 'spent': 756,\n",
              " 'clothes': 757,\n",
              " 'company': 758,\n",
              " 'far.': 759,\n",
              " 'version': 760,\n",
              " 'recommend.': 761,\n",
              " 'wouldn’t': 762,\n",
              " 'Used': 763,\n",
              " 'fact': 764,\n",
              " 'reliable': 765,\n",
              " 'free': 766,\n",
              " 'con': 767,\n",
              " 'install.': 768,\n",
              " 'watching': 769,\n",
              " 'etc.': 770,\n",
              " 'To': 771,\n",
              " 'difficult': 772,\n",
              " '!': 773,\n",
              " 'black': 774,\n",
              " 'that,': 775,\n",
              " 'Best': 776,\n",
              " 'matter': 777,\n",
              " 'strong': 778,\n",
              " 'time,': 779,\n",
              " 'product,': 780,\n",
              " 'refund': 781,\n",
              " 'years.': 782,\n",
              " 'repair': 783,\n",
              " 'piece': 784,\n",
              " 'feels': 785,\n",
              " 'yet': 786,\n",
              " 'figure': 787,\n",
              " 'Its': 788,\n",
              " 'opened': 789,\n",
              " 'recommended': 790,\n",
              " 'others': 791,\n",
              " 'faster': 792,\n",
              " 'phone.': 793,\n",
              " 'file': 794,\n",
              " 'computer,': 795,\n",
              " 'previous': 796,\n",
              " 'window': 797,\n",
              " 'via': 798,\n",
              " 'upgraded': 799,\n",
              " 'PS4': 800,\n",
              " 'however': 801,\n",
              " 'wife': 802,\n",
              " 'ended': 803,\n",
              " 'drop': 804,\n",
              " 'IT': 805,\n",
              " 'in,': 806,\n",
              " 'fast,': 807,\n",
              " 'Also': 808,\n",
              " 'believe': 809,\n",
              " 'constantly': 810,\n",
              " 'usually': 811,\n",
              " 'liked': 812,\n",
              " 'stick': 813,\n",
              " 'close': 814,\n",
              " 'twice': 815,\n",
              " 'cord': 816,\n",
              " 'Definitely': 817,\n",
              " 'kind': 818,\n",
              " 'bottom': 819,\n",
              " 'literally': 820,\n",
              " 'dead': 821,\n",
              " 'perfect.': 822,\n",
              " 'Don’t': 823,\n",
              " 'single': 824,\n",
              " 'click': 825,\n",
              " 'leave': 826,\n",
              " 'expected.': 827,\n",
              " 'Everything': 828,\n",
              " 'plenty': 829,\n",
              " 'SD': 830,\n",
              " 'charger': 831,\n",
              " 'boost': 832,\n",
              " 'purchasing': 833,\n",
              " 'important': 834,\n",
              " 'care': 835,\n",
              " 'me,': 836,\n",
              " 'un': 837,\n",
              " 'isn’t': 838,\n",
              " 'couldn’t': 839,\n",
              " 'turned': 840,\n",
              " 'issue.': 841,\n",
              " 'Affresh': 842,\n",
              " 'place': 843,\n",
              " 'internal': 844,\n",
              " '2TB': 845,\n",
              " 'playing': 846,\n",
              " 'TV': 847,\n",
              " 'remove': 848,\n",
              " 'connection.': 849,\n",
              " 'box.': 850,\n",
              " 'support.': 851,\n",
              " 'to.': 852,\n",
              " '(I': 853,\n",
              " 'audio': 854,\n",
              " 'works.': 855,\n",
              " 'Really': 856,\n",
              " 'broken': 857,\n",
              " 'smells': 858,\n",
              " 'regular': 859,\n",
              " 'name': 860,\n",
              " 'Purchased': 861,\n",
              " 'this,': 862,\n",
              " 'guess': 863,\n",
              " 'calls': 864,\n",
              " 'allow': 865,\n",
              " 'programs': 866,\n",
              " 'stars': 867,\n",
              " 'complaints': 868,\n",
              " 'immediately': 869,\n",
              " 'lose': 870,\n",
              " 'boot': 871,\n",
              " 'files.': 872,\n",
              " 'THE': 873,\n",
              " 'airpod': 874,\n",
              " 'Hard': 875,\n",
              " 'business': 876,\n",
              " 'live': 877,\n",
              " 'soon': 878,\n",
              " 'fan': 879,\n",
              " 'itself': 880,\n",
              " 'dropped': 881,\n",
              " 'design': 882,\n",
              " 'wash': 883,\n",
              " 'ran': 884,\n",
              " 'book': 885,\n",
              " 'us': 886,\n",
              " 'them,': 887,\n",
              " 'off.': 888,\n",
              " 'that’s': 889,\n",
              " 'I’ll': 890,\n",
              " 'day.': 891,\n",
              " 'myself': 892,\n",
              " 'you.': 893,\n",
              " 'far,': 894,\n",
              " 'First': 895,\n",
              " 'worked.': 896,\n",
              " 'graphics': 897,\n",
              " '15': 898,\n",
              " 'died': 899,\n",
              " 'extended': 900,\n",
              " 'perfectly.': 901,\n",
              " 'needed.': 902,\n",
              " 'lasted': 903,\n",
              " 'seemed': 904,\n",
              " 'desktop': 905,\n",
              " 'weak': 906,\n",
              " 'Nothing': 907,\n",
              " 'Christmas': 908,\n",
              " 'entire': 909,\n",
              " 'package': 910,\n",
              " 'except': 911,\n",
              " 'often': 912,\n",
              " 'saying': 913,\n",
              " 'data.': 914,\n",
              " '11': 915,\n",
              " 'dont': 916,\n",
              " 'water': 917,\n",
              " 'plan': 918,\n",
              " 'Overall': 919,\n",
              " 'rather': 920,\n",
              " 'Maybe': 921,\n",
              " 'unable': 922,\n",
              " 'charged': 923,\n",
              " 'games.': 924,\n",
              " 'cancellation': 925,\n",
              " 'WPS': 926,\n",
              " 'Still': 927,\n",
              " 'With': 928,\n",
              " 'notice': 929,\n",
              " 'flattering': 930,\n",
              " 'wait': 931,\n",
              " 'TO': 932,\n",
              " 'fresh': 933,\n",
              " 'iPhone': 934,\n",
              " 'streaming': 935,\n",
              " 'AND': 936,\n",
              " 'advertised.': 937,\n",
              " 'basically': 938,\n",
              " 'newer': 939,\n",
              " 'generation': 940,\n",
              " 'home.': 941,\n",
              " 'simply': 942,\n",
              " 'life.': 943,\n",
              " 'error': 944,\n",
              " 'advertised': 945,\n",
              " '100%': 946,\n",
              " 'material': 947,\n",
              " 'coming': 948,\n",
              " 'needs.': 949,\n",
              " 'not.': 950,\n",
              " 'Drive': 951,\n",
              " 'Screen': 952,\n",
              " 'hot': 953,\n",
              " 'compared': 954,\n",
              " 'formatted': 955,\n",
              " 'moved': 956,\n",
              " 'sounds': 957,\n",
              " '4GB': 958,\n",
              " 'plus': 959,\n",
              " 'contacted': 960,\n",
              " 'understand': 961,\n",
              " 'factory': 962,\n",
              " 'directly': 963,\n",
              " 'Ryzen': 964,\n",
              " 'dress.': 965,\n",
              " 'Also,': 966,\n",
              " 'you’re': 967,\n",
              " 'THIS': 968,\n",
              " 'daily': 969,\n",
              " 'lights': 970,\n",
              " 'quality,': 971,\n",
              " 'person': 972,\n",
              " 'contact': 973,\n",
              " 'saw': 974,\n",
              " 'se': 975,\n",
              " 'college': 976,\n",
              " 'router,': 977,\n",
              " 'taking': 978,\n",
              " 'build': 979,\n",
              " 'loading': 980,\n",
              " 'DO': 981,\n",
              " 'door': 982,\n",
              " 'broke': 983,\n",
              " 'setup.': 984,\n",
              " 'screen,': 985,\n",
              " 'surprised': 986,\n",
              " 'brand.': 987,\n",
              " 'near': 988,\n",
              " 'disappointed.': 989,\n",
              " 'case.': 990,\n",
              " 'listening': 991,\n",
              " 'features': 992,\n",
              " 'smelling': 993,\n",
              " 'figured': 994,\n",
              " 'days.': 995,\n",
              " 'description': 996,\n",
              " 'one,': 997,\n",
              " 'information': 998,\n",
              " 'giving': 999,\n",
              " 'downloaded': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "vocab_to_int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VM4lNIPZXUa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1449e5-a0fd-438e-f598-c4a156aec854"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 386, 23, 242, 1881, 16, 11, 1914, 1699, 231, 3437, 8, 10181, 4, 5, 12706, 535], [2, 106, 11, 2209, 1845, 6, 3, 41, 755, 4, 6, 13, 5, 18071, 25, 266, 48, 23, 822, 237, 2695], [149, 35, 3306, 600, 7, 7602, 14, 5011, 21, 1269, 8, 606, 1200, 2, 90, 5, 18072, 18073, 18074, 3880, 1, 227, 4, 20, 572, 616, 2, 27, 6, 538, 2, 78, 2774, 1, 1914]]\n"
          ]
        }
      ],
      "source": [
        "#encoding of reviews (replace words in our reviews by integers)\n",
        "reviews_int = []\n",
        "for review in text:\n",
        "    r = [vocab_to_int[w] for w in review.split()]\n",
        "    reviews_int.append(r)\n",
        "print (reviews_int[0:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iD2aASvXdGx"
      },
      "outputs": [],
      "source": [
        "labels = np.array(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMwF82iXXhLN"
      },
      "outputs": [],
      "source": [
        "#converting to binary class\n",
        "l=[]\n",
        "for i in labels:\n",
        "  if(i==0 or i==1 or i==2):\n",
        "    i=0\n",
        "  elif(i==3 or i==4 or i==5):\n",
        "    i=1\n",
        "  l.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UDXqrvJXmtW"
      },
      "outputs": [],
      "source": [
        "label = np.array(l)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTG_0fb9Xq4Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6cca0f8-6757-4354-99de-1f00a41b27d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFxWgu1MXvmp"
      },
      "outputs": [],
      "source": [
        "def pad_input(sentences, seq_len):\n",
        "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
        "    for ii, review in enumerate(sentences):\n",
        "        if len(review) != 0:\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4rAW-xIX2zH"
      },
      "outputs": [],
      "source": [
        "seq_len = 200  # The length that the sentences will be padded/shortened to\n",
        "\n",
        "reviews = pad_input(reviews_int, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Jl4z65rX3du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425d0fda-4f9c-4f0e-baee-42a327655008"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     2,   386,    23,   242,  1881,    16,\n",
              "          11,  1914,  1699,   231,  3437,     8, 10181,     4,     5,\n",
              "       12706,   535])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "reviews[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhinKYr1X3fn"
      },
      "outputs": [],
      "source": [
        "#80% train, 10% test & 10% validation\n",
        "split_frac = 0.8\n",
        "len_feat = len(reviews)\n",
        "train_x = reviews[0:int(split_frac*len_feat)]\n",
        "train_y = label[0:int(split_frac*len_feat)]\n",
        "remaining_x = reviews[int(split_frac*len_feat):]\n",
        "remaining_y = label[int(split_frac*len_feat):]\n",
        "valid_x = remaining_x[0:int(len(remaining_x)*0.5)]\n",
        "valid_y = remaining_y[0:int(len(remaining_y)*0.5)]\n",
        "test_x = remaining_x[int(len(remaining_x)*0.5):]\n",
        "test_y = remaining_y[int(len(remaining_y)*0.5):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBXtbTrCX3io"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size,drop_last=True)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size,drop_last=True)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size,drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO3MavXaX3kt"
      },
      "outputs": [],
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw97bglWX3nr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7094665e-7640-4119-ca17-f7f75ef023af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([64, 200])\n",
            "Sample input: \n",
            " tensor([[    0,     0,     0,  ...,  1564,  2170,  1051],\n",
            "        [    0,     0,     0,  ...,  3884, 35008,  6104],\n",
            "        [    0,     0,     0,  ...,   389,   105,   120],\n",
            "        ...,\n",
            "        [    0,     0,     0,  ...,  2919,     4,  1372],\n",
            "        [    0,     0,     0,  ...,   108,    44,  3438],\n",
            "        [    0,     0,     0,  ..., 13109,   219,  9789]])\n",
            "\n",
            "Sample label size:  torch.Size([64])\n",
            "Sample label: \n",
            " tensor([1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
            "        1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
            "        0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0])\n"
          ]
        }
      ],
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "sample_x, sample_y = next(dataiter)\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYtIry3NZjCq"
      },
      "source": [
        "LSTM(long short-term memory networks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKZTWePeX3pp"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim).to(device)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers,dropout=drop_prob, batch_first=True)\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3).to(device)\n",
        "\n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size).to(device)\n",
        "        self.sig = nn.Sigmoid().to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "\n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).normal_().to(device),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).normal_().to(device))\n",
        "\n",
        "        return hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk8TDYGoZypD"
      },
      "source": [
        "GRU(Gated recurrent units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUPU9FqKX3r5"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim).to(device)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, n_layers,dropout=drop_prob, batch_first=True)\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3).to(device)\n",
        "\n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size).to(device)\n",
        "        self.sig = nn.Sigmoid().to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        gru_out, hidden = self.gru(embeds, hidden)\n",
        "\n",
        "        # stack up lstm outputs\n",
        "        gru_out = gru_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(gru_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "\n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "\n",
        "        hidden = weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device)\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgS03VZeaBEz"
      },
      "source": [
        "Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvNG10PjX3tx"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
        "output_size = 1\n",
        "embedding_dim = 400 #\n",
        "batch_size = 64\n",
        "device = torch.device(\"cuda\")\n",
        "hidden_dim = 256\n",
        "n_layers = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_bcxgYQaJT-"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MY1in2_GX3wN"
      },
      "outputs": [],
      "source": [
        "# training params\n",
        "def train(train_loader,valid_loader,epochs,model_type):\n",
        "  if model_type == \"LSTM\":\n",
        "    net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers).to(device)\n",
        "  elif (model_type == \"GRU\"):\n",
        "    net = GRU(vocab_size, output_size, embedding_dim, hidden_dim, n_layers).to(device)\n",
        "  lr=0.001\n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "  counter = 0\n",
        "  print_every = 100\n",
        "  clip=5 # gradient clipping\n",
        "  net.train()\n",
        "  # train for some number of epochs\n",
        "  for e in range(epochs):\n",
        "      # initialize hidden state\n",
        "      h = net.init_hidden(batch_size)\n",
        "\n",
        "      # batch loop\n",
        "      for inputs, labels in train_loader:\n",
        "          counter += 1\n",
        "\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          # Creating new variables for the hidden state, otherwise\n",
        "          # we'd backprop through the entire training history\n",
        "          if model_type == \"GRU\":\n",
        "            h = h.data.to(device)\n",
        "          elif model_type == \"LSTM\":\n",
        "            h = tuple([each.data.to(device) for each in h])\n",
        "          # zero accumulated gradients\n",
        "          net.zero_grad()\n",
        "\n",
        "          # get the output from the model\n",
        "          inputs = inputs.type(torch.LongTensor).to(device)\n",
        "          output, h = net(inputs, h)\n",
        "          #print(output[0])\n",
        "          # calculate the loss and perform backprop\n",
        "          #print(\"shape of output\", output.shape)\n",
        "          #print(\"shape of labels\", labels.shape)\n",
        "          loss = criterion(output.squeeze(), labels.float())\n",
        "          loss.backward()\n",
        "          # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "          nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "          optimizer.step()\n",
        "\n",
        "          # loss stats\n",
        "          if counter % print_every == 0:\n",
        "              # Get validation loss\n",
        "              val_h = net.init_hidden(batch_size)\n",
        "              val_losses = []\n",
        "              net.eval()\n",
        "              for inputs, labels in valid_loader:\n",
        "\n",
        "                  # Creating new variables for the hidden state, otherwise\n",
        "                  # we'd backprop through the entire training history\n",
        "                  if model_type == \"GRU\":\n",
        "                    val_h = val_h.data.to(device)\n",
        "                  elif (model_type == \"LSTM\"):\n",
        "                    val_h = tuple([each.data.to(device) for each in val_h])\n",
        "\n",
        "                  inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                  inputs = inputs.type(torch.LongTensor).to(device)\n",
        "                  output, val_h = net(inputs, val_h)\n",
        "                  val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                  val_losses.append(val_loss.item())\n",
        "\n",
        "              net.train()\n",
        "              print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                    \"Model:{}...\".format(model_type),\n",
        "                    \"Step: {}...\".format(counter),\n",
        "                    \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                    \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
        "  return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1i0hntgX3zI"
      },
      "outputs": [],
      "source": [
        "train_on_gpu = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4mdV9nHafVN"
      },
      "source": [
        "Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6TYwL5VX32F"
      },
      "outputs": [],
      "source": [
        "def test(net,test_loader,model_type):\n",
        "\n",
        "  # Get test data loss and accuracy\n",
        "  lr=0.001\n",
        "  criterion = nn.BCELoss()\n",
        "  optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "\n",
        "  test_losses = [] # track loss\n",
        "  num_correct = 0\n",
        "\n",
        "  # init hidden state\n",
        "  h = net.init_hidden(batch_size)\n",
        "\n",
        "  net.eval()\n",
        "  # iterate over test data\n",
        "  for inputs, labels in test_loader:\n",
        "\n",
        "      # Creating new variables for the hidden state, otherwise\n",
        "      # we'd backprop through the entire training history\n",
        "      if model_type == \"GRU\":\n",
        "        h = h.data.to(device)\n",
        "      elif (model_type == \"LSTM\"):\n",
        "        h = tuple([each.data.to(device) for each in h])\n",
        "\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      # get predicted outputs\n",
        "      inputs = inputs.type(torch.LongTensor).to(device)\n",
        "      output, h = net(inputs, h)\n",
        "\n",
        "      # calculate loss\n",
        "      test_loss = criterion(output.squeeze(), labels.float())\n",
        "      test_losses.append(test_loss.item())\n",
        "\n",
        "      # convert output probabilities to predicted class (0 or 1)\n",
        "      pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "      # compare predictions to true label\n",
        "      correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "      correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "      num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "  # -- stats! -- ##\n",
        "  # avg test loss\n",
        "  print(\"Model: {}\".format(model_type))\n",
        "  print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "  # accuracy over all test data\n",
        "  test_acc = num_correct/len(test_loader.dataset)\n",
        "  print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6bxTymuaukm"
      },
      "source": [
        "Evaluating our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6v25K9XbYzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e86293-e816-49d3-d5a1-9acc51677e6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXMdEvtgcQmn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "319d99ae-e89d-48aa-c87b-90c344968386"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrADRaOUX35A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e287f7b9-ff7d-49b2-918d-5afecc6e501b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/15... Model:LSTM... Step: 100... Loss: 0.408903... Val Loss: 0.435114\n",
            "Epoch: 1/15... Model:LSTM... Step: 200... Loss: 0.305120... Val Loss: 0.388806\n",
            "Epoch: 2/15... Model:LSTM... Step: 300... Loss: 0.312532... Val Loss: 0.404169\n",
            "Epoch: 2/15... Model:LSTM... Step: 400... Loss: 0.265066... Val Loss: 0.357733\n",
            "Epoch: 2/15... Model:LSTM... Step: 500... Loss: 0.311869... Val Loss: 0.345742\n",
            "Epoch: 3/15... Model:LSTM... Step: 600... Loss: 0.162901... Val Loss: 0.325333\n",
            "Epoch: 3/15... Model:LSTM... Step: 700... Loss: 0.147773... Val Loss: 0.397634\n",
            "Epoch: 3/15... Model:LSTM... Step: 800... Loss: 0.491617... Val Loss: 0.406979\n",
            "Epoch: 4/15... Model:LSTM... Step: 900... Loss: 0.131135... Val Loss: 0.412895\n",
            "Epoch: 4/15... Model:LSTM... Step: 1000... Loss: 0.107986... Val Loss: 0.482089\n",
            "Epoch: 4/15... Model:LSTM... Step: 1100... Loss: 0.111975... Val Loss: 0.466782\n",
            "Epoch: 5/15... Model:LSTM... Step: 1200... Loss: 0.009523... Val Loss: 0.498578\n",
            "Epoch: 5/15... Model:LSTM... Step: 1300... Loss: 0.068567... Val Loss: 0.658093\n",
            "Epoch: 5/15... Model:LSTM... Step: 1400... Loss: 0.014160... Val Loss: 0.546000\n",
            "Epoch: 6/15... Model:LSTM... Step: 1500... Loss: 0.005604... Val Loss: 0.656659\n",
            "Epoch: 6/15... Model:LSTM... Step: 1600... Loss: 0.027954... Val Loss: 0.713838\n",
            "Epoch: 6/15... Model:LSTM... Step: 1700... Loss: 0.046308... Val Loss: 0.639848\n",
            "Epoch: 7/15... Model:LSTM... Step: 1800... Loss: 0.005430... Val Loss: 0.718758\n",
            "Epoch: 7/15... Model:LSTM... Step: 1900... Loss: 0.044430... Val Loss: 0.751990\n",
            "Epoch: 7/15... Model:LSTM... Step: 2000... Loss: 0.039980... Val Loss: 0.740773\n",
            "Epoch: 8/15... Model:LSTM... Step: 2100... Loss: 0.006911... Val Loss: 0.755601\n",
            "Epoch: 8/15... Model:LSTM... Step: 2200... Loss: 0.009340... Val Loss: 0.767839\n",
            "Epoch: 8/15... Model:LSTM... Step: 2300... Loss: 0.012422... Val Loss: 0.735705\n",
            "Epoch: 9/15... Model:LSTM... Step: 2400... Loss: 0.014203... Val Loss: 0.794438\n",
            "Epoch: 9/15... Model:LSTM... Step: 2500... Loss: 0.050266... Val Loss: 0.671078\n",
            "Epoch: 9/15... Model:LSTM... Step: 2600... Loss: 0.050838... Val Loss: 0.746721\n",
            "Epoch: 10/15... Model:LSTM... Step: 2700... Loss: 0.038418... Val Loss: 0.737128\n",
            "Epoch: 10/15... Model:LSTM... Step: 2800... Loss: 0.018759... Val Loss: 0.885082\n",
            "Epoch: 10/15... Model:LSTM... Step: 2900... Loss: 0.017207... Val Loss: 0.816739\n",
            "Epoch: 11/15... Model:LSTM... Step: 3000... Loss: 0.006869... Val Loss: 0.835604\n",
            "Epoch: 11/15... Model:LSTM... Step: 3100... Loss: 0.000713... Val Loss: 0.861552\n",
            "Epoch: 11/15... Model:LSTM... Step: 3200... Loss: 0.003279... Val Loss: 0.767524\n",
            "Epoch: 12/15... Model:LSTM... Step: 3300... Loss: 0.029351... Val Loss: 0.909471\n",
            "Epoch: 12/15... Model:LSTM... Step: 3400... Loss: 0.032829... Val Loss: 0.875359\n",
            "Epoch: 12/15... Model:LSTM... Step: 3500... Loss: 0.006786... Val Loss: 0.787462\n",
            "Epoch: 13/15... Model:LSTM... Step: 3600... Loss: 0.002431... Val Loss: 0.884228\n",
            "Epoch: 13/15... Model:LSTM... Step: 3700... Loss: 0.001852... Val Loss: 0.957748\n",
            "Epoch: 13/15... Model:LSTM... Step: 3800... Loss: 0.001397... Val Loss: 0.959337\n",
            "Epoch: 14/15... Model:LSTM... Step: 3900... Loss: 0.002931... Val Loss: 0.835500\n",
            "Epoch: 14/15... Model:LSTM... Step: 4000... Loss: 0.000552... Val Loss: 0.917231\n",
            "Epoch: 14/15... Model:LSTM... Step: 4100... Loss: 0.009199... Val Loss: 1.038964\n",
            "Epoch: 15/15... Model:LSTM... Step: 4200... Loss: 0.032188... Val Loss: 1.009522\n",
            "Epoch: 15/15... Model:LSTM... Step: 4300... Loss: 0.000777... Val Loss: 0.987204\n",
            "Epoch: 15/15... Model:LSTM... Step: 4400... Loss: 0.000187... Val Loss: 1.086886\n",
            "Epoch: 1/15... Model:GRU... Step: 100... Loss: 0.440293... Val Loss: 0.496808\n",
            "Epoch: 1/15... Model:GRU... Step: 200... Loss: 0.349899... Val Loss: 0.411205\n",
            "Epoch: 2/15... Model:GRU... Step: 300... Loss: 0.323901... Val Loss: 0.390629\n",
            "Epoch: 2/15... Model:GRU... Step: 400... Loss: 0.317270... Val Loss: 0.452557\n",
            "Epoch: 2/15... Model:GRU... Step: 500... Loss: 0.283515... Val Loss: 0.334846\n",
            "Epoch: 3/15... Model:GRU... Step: 600... Loss: 0.140751... Val Loss: 0.340962\n",
            "Epoch: 3/15... Model:GRU... Step: 700... Loss: 0.117993... Val Loss: 0.438295\n",
            "Epoch: 3/15... Model:GRU... Step: 800... Loss: 0.188566... Val Loss: 0.424383\n",
            "Epoch: 4/15... Model:GRU... Step: 900... Loss: 0.067660... Val Loss: 0.423313\n",
            "Epoch: 4/15... Model:GRU... Step: 1000... Loss: 0.141940... Val Loss: 0.611849\n",
            "Epoch: 4/15... Model:GRU... Step: 1100... Loss: 0.112795... Val Loss: 0.529997\n",
            "Epoch: 5/15... Model:GRU... Step: 1200... Loss: 0.052425... Val Loss: 0.507250\n",
            "Epoch: 5/15... Model:GRU... Step: 1300... Loss: 0.002700... Val Loss: 0.596110\n",
            "Epoch: 5/15... Model:GRU... Step: 1400... Loss: 0.014119... Val Loss: 0.710220\n",
            "Epoch: 6/15... Model:GRU... Step: 1500... Loss: 0.011309... Val Loss: 0.799281\n",
            "Epoch: 6/15... Model:GRU... Step: 1600... Loss: 0.035318... Val Loss: 0.930303\n",
            "Epoch: 6/15... Model:GRU... Step: 1700... Loss: 0.057418... Val Loss: 0.688306\n",
            "Epoch: 7/15... Model:GRU... Step: 1800... Loss: 0.005310... Val Loss: 0.713983\n",
            "Epoch: 7/15... Model:GRU... Step: 1900... Loss: 0.067827... Val Loss: 0.778366\n",
            "Epoch: 7/15... Model:GRU... Step: 2000... Loss: 0.120243... Val Loss: 0.799075\n",
            "Epoch: 8/15... Model:GRU... Step: 2100... Loss: 0.009462... Val Loss: 0.757570\n",
            "Epoch: 8/15... Model:GRU... Step: 2200... Loss: 0.009943... Val Loss: 0.772988\n",
            "Epoch: 8/15... Model:GRU... Step: 2300... Loss: 0.006606... Val Loss: 0.763957\n",
            "Epoch: 9/15... Model:GRU... Step: 2400... Loss: 0.004158... Val Loss: 0.750578\n",
            "Epoch: 9/15... Model:GRU... Step: 2500... Loss: 0.005054... Val Loss: 0.886769\n",
            "Epoch: 9/15... Model:GRU... Step: 2600... Loss: 0.002971... Val Loss: 0.907136\n",
            "Epoch: 10/15... Model:GRU... Step: 2700... Loss: 0.008751... Val Loss: 1.021306\n",
            "Epoch: 10/15... Model:GRU... Step: 2800... Loss: 0.003462... Val Loss: 1.128058\n",
            "Epoch: 10/15... Model:GRU... Step: 2900... Loss: 0.002653... Val Loss: 0.924455\n",
            "Epoch: 11/15... Model:GRU... Step: 3000... Loss: 0.002063... Val Loss: 1.000140\n",
            "Epoch: 11/15... Model:GRU... Step: 3100... Loss: 0.004825... Val Loss: 0.940238\n",
            "Epoch: 11/15... Model:GRU... Step: 3200... Loss: 0.006006... Val Loss: 1.071435\n",
            "Epoch: 12/15... Model:GRU... Step: 3300... Loss: 0.000716... Val Loss: 1.020916\n",
            "Epoch: 12/15... Model:GRU... Step: 3400... Loss: 0.016129... Val Loss: 1.008942\n",
            "Epoch: 12/15... Model:GRU... Step: 3500... Loss: 0.005648... Val Loss: 0.989218\n",
            "Epoch: 13/15... Model:GRU... Step: 3600... Loss: 0.042713... Val Loss: 0.960203\n",
            "Epoch: 13/15... Model:GRU... Step: 3700... Loss: 0.000446... Val Loss: 0.943443\n",
            "Epoch: 13/15... Model:GRU... Step: 3800... Loss: 0.008002... Val Loss: 0.984754\n",
            "Epoch: 14/15... Model:GRU... Step: 3900... Loss: 0.011087... Val Loss: 1.026920\n",
            "Epoch: 14/15... Model:GRU... Step: 4000... Loss: 0.003550... Val Loss: 0.958593\n",
            "Epoch: 14/15... Model:GRU... Step: 4100... Loss: 0.035744... Val Loss: 1.026518\n",
            "Epoch: 15/15... Model:GRU... Step: 4200... Loss: 0.010088... Val Loss: 0.962864\n",
            "Epoch: 15/15... Model:GRU... Step: 4300... Loss: 0.000348... Val Loss: 0.917841\n",
            "Epoch: 15/15... Model:GRU... Step: 4400... Loss: 0.007740... Val Loss: 0.938547\n"
          ]
        }
      ],
      "source": [
        "lstm = train(train_loader,valid_loader,15,model_type=\"LSTM\")\n",
        "gru = train(train_loader,valid_loader,15,model_type=\"GRU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcY3Djf0a7aZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b4b3dc-3142-432d-fc15-f6e1f4b0d3bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: LSTM\n",
            "Test loss: 0.918\n",
            "Test accuracy: 0.858\n",
            "Model: GRU\n",
            "Test loss: 0.773\n",
            "Test accuracy: 0.853\n"
          ]
        }
      ],
      "source": [
        "test(lstm,test_loader,model_type =\"LSTM\")\n",
        "test(gru,test_loader,model_type=\"GRU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWSVyo3reS-y"
      },
      "source": [
        "Predicting the sentiment of user data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRG4DqOReSfm"
      },
      "outputs": [],
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_review(test_review):\n",
        "    test_review = test_review.lower() # lowercase\n",
        "    # get rid of punctuation\n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "\n",
        "    # splitting by spaces\n",
        "    test_words = test_text.split()\n",
        "\n",
        "    # tokens\n",
        "    test_ints = []\n",
        "    test_ints.append([vocab_to_int[word] for word in test_words])\n",
        "\n",
        "    return test_ints\n",
        "\n",
        "\n",
        "def predict(net, test_review, sequence_length=200):\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    # tokenize review\n",
        "    test_ints = tokenize_review(test_review)\n",
        "\n",
        "    # pad tokenized sequence\n",
        "    seq_length=sequence_length\n",
        "    features = pad_input(test_ints, seq_length)\n",
        "\n",
        "    # convert to tensor to pass into your model\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "\n",
        "    batch_size = feature_tensor.size(0)\n",
        "\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    feature_tensor = feature_tensor.to(device)\n",
        "\n",
        "    # get the output from the model\n",
        "    output, h = net(feature_tensor, h)\n",
        "\n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output)\n",
        "    # printing output value, before rounding\n",
        "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
        "\n",
        "    # print custom response\n",
        "    if(pred.item()==1):\n",
        "        print(\"Positive review detected!\")\n",
        "    else:\n",
        "        print(\"Negative review detected.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMNYLylCedLR",
        "outputId": "ed83af27-3273-488c-9e51-3aafc21861c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of model you want to test on GRU\n",
            "Prediction value, pre-rounding: 0.999995\n",
            "Positive review detected!\n"
          ]
        }
      ],
      "source": [
        "test_review = 'This product was  good. I love it.'\n",
        "seq_length=200 # good to use the length that was trained on\n",
        "model_type= input(\"Type of model you want to test on \")\n",
        "if model_type == \"LSTM\":\n",
        "  net = lstm\n",
        "elif (model_type == \"GRU\"):\n",
        "  net = gru\n",
        "\n",
        "predict(net, test_review, seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AII01wQEq0-m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVGhUFubq1Ho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "284a8603-57ba-423e-f393-8c64e23df3f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the review : DISGUSTING\n",
            "Type of model you want to test on GRU\n",
            "Prediction value, pre-rounding: 0.001405\n",
            "Negative review detected.\n"
          ]
        }
      ],
      "source": [
        "test_review = input(\"Enter the review : \")\n",
        "seq_length=200 # good to use the length that was trained on\n",
        "model_type= input(\"Type of model you want to test on \")\n",
        "if model_type == \"LSTM\":\n",
        "  net = lstm\n",
        "elif (model_type == \"GRU\"):\n",
        "  net = gru\n",
        "\n",
        "predict(net, test_review, seq_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLdS8xAvfOp2"
      },
      "source": [
        "The key difference between GRU and LSTM is that GRU's bag has two gates that are reset and update while LSTM has three gates that are input, output, forget. GRU is less complex than LSTM because it has less number of gates.\n",
        "\n",
        "If the dataset is small then GRU is preferred otherwise LSTM for the larger dataset.\n",
        "\n",
        "GRU exposes the complete memory and hidden layers but LSTM doesn't."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSgJZ0/jYjr62ucNL6h8RU"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}